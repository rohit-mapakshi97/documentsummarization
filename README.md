# Text Summarization with Fine-Tuned LLMs: BART, T5, and TextRank
This project focuses on fine-tuning large language models (LLMs) like BART and T5, alongside the unsupervised TextRank method, to generate concise summaries of WikiHow articles. Pretrained T5 and BART models were fine-tuned on the dataset, significantly improving summarization performance, while TextRank used an extractive approach. BART outperformed the other models with a ROUGE-1 score of 0.25, and the study also examined the impact of word embeddings like Word2Vec and WordPiece. The project included the development of a web application, with BART achieving BLEU and ROUGE-L scores of 0.72 and 0.68, respectively.
